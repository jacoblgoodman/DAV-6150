{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "# Data Science: Module 3\n",
    "### M3 Practical Challenge: Cleaning a Messy Data Set\n",
    "#### Alan Leidner working with Jacob Goodman Sep 20, 2021\n",
    "Assignment: https://yu.instructure.com/courses/50398/assignments/191949?module_item_id=704962"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook will ------\n",
    "\n",
    "1. [Exploratory Data Analysis](#Analysis)\n",
    "2. [Regression Model Construction & Evaluation](#Model)\n",
    "3. [Conclusion](#Conclusion)\n",
    "\n",
    "DataSource: ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a id='Analysis'></a>\n",
    "The dataset was loaded into the DAV 6150 Github Repository here: https://github.com/yuleidner/DAV-6150/blob/main/M1%26M2/M2_Data.csv. This notebook will now load the table into a Pandas dataframe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# load the train_test_split function from the sklearn.model_selection module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read a set of sample data from github. It contains information related to cars and insurance\n",
    "filename = \"https://raw.githubusercontent.com/yuleidner/DAV-6150/main/M1%26M2/M2_Data.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "pd.set_option('display.max_columns', None) #expands df to display all columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment requires the application of many of the data preparation concepts covered in the required readings for Module 3. Specifically, you will be exploring and “cleaning” a wine attributes data set that suffers from a variety of data integrity + usability issues.\n",
    "\n",
    "You will perform a thorough EDA and then use your Python skills to perform appropriate data preparation tasks to address the data integrity + usability issues you identified via your EDA work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Attribute Description\n",
    "INDEX Unique ID\n",
    "TARGETResponse Variable (indicates # of cases of wine sold)\n",
    "AcidIndexMeasures total acidity of wine via a weighted average \n",
    "Alcohol Alcohol Content\n",
    "Chlorides Chloride content of the wine\n",
    "CitricAcid Citric Acid content of the wine\n",
    "Density Density of the wine\n",
    "FixedAcidity FixedAcidity of the wine\n",
    "FreeSulfurDioxide Sulfur Dioxide content of the wine\n",
    "LabelAppeal Subjective marketing score that indicates the appeal of the design of the label on the bottle\n",
    "ResidualSugar Residual sugar content of the wine\n",
    "STARS Wine rating as determined by experts (4 = excellent; 1 = Poor\n",
    "Sulphates Sulfate content of the wine\n",
    "TotalSulfurDioxideTotal sulfur dioxide content of the wine\n",
    "VolatileAcidity Volatile acid content of the wine\n",
    "pH pH of the wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the provided M3_Data.csv file to your DAV 6150 Github Repository. \n",
    "\n",
    "2. Then, using a Jupyter Notebook, read the data set from your Github repository and load it into a Pandas dataframe.  \n",
    "3. Using your Pythonskills, perform exploratory data analysis (EDA) on all of the provided data attributes and document your findings. Your EDA writeup should include any insights you are able to derive from your statistical analysis of the attributes and the accompanying exploratory graphics you create(e.g., bar plots, box plots, histograms, line plots, etc.). It is up to you as the data science practitioner to decide how you go about your EDA, including selecting appropriate statistical metrics to be calculated + which types of exploratory graphics to make use of. You should also identify any and all potential data integrity issues (e.g., missing data values; invalid data values; etc.)as well as data distribution issues (e.g., severe skew that can potentially impede the training/performance of a machinelearning model)and, based on your analysis, determine whether any data attributes might need to be transformed prior to being used within a machine learning model. Your goal should be to provide an EDA that is thorough and succinct without it being so detailed that a reader will lose interest in it. \n",
    "\n",
    "4. Using your Python skills, perform appropriate data preparation tasks relative to the data integrity + usability issues you identified via your EDA work.Describe the ways in which you have transformed / prepared the data for use within a machine learning algorithm, e.g., have you deleted any observations? Used imputation to fill missing data values? Created any new variables? Transformed data distributions via mathematical transforms (e.g., Box-Cox, logarithms, etc.) or binningto make the data more “usable”for model training? etc. Be sure to explain your justification for each adjustment you have made to the data.\n",
    "\n",
    "5. Using Python, re-run your EDA analysis on any variables you have adjusted during Data Preparation and compare / contrast your results to those you saw prior to performing your Data Preparation adjustments. Describe how each of your Data Preparation adjustments have improved the data set for purposes of using it within a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your deliverable for this assignmentis your Jupyter Notebook. It should contain a combination of Python code cells and explanatory narratives contained within properly formatted Markdown cells. The Notebook should contain (at a minimum) the following sections (including the relevant Python code for each section):1)Introduction(5Points):  Summarize the problem + explain the steps you plan to take to address the problem2)Exploratory Data Analysis(35Points): Explain + present your EDA work including any conclusions you draw from your analysis regarding the integrity + usability of the data in its raw state. This section should include any Python code used for the EDA3)Data Preparation(45Points): Describe + show the steps you have taken to address the data integrity + usability issues you identified in your EDA. This section should include any Python code used for Data Preparation4)Prepped Data Review(10 Points): Explain + present your post-Data Prep EDA analysis. This section should include any Python code used for re-running your EDA on the variables adjusted during your Data Preparation work.5)Conclusions(5Points) Small groups should identity all group members at the start of the Jupyter Notebook and each team member should submit their own copy of the team’s work within Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
